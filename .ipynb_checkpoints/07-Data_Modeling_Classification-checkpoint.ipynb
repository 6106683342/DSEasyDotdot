{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data Modeling : Classification\n",
    "\n",
    "    การสร้างโมเดล Classification สำหรับการจัดประเภทกลุ่มต่างๆ\n",
    "\n",
    "                                                                                        Data Science ง่าย . . by New ew ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install python-graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('06_vertebrate.csv',header='infer')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Class'] = data['Class'].replace(['fishes','birds','amphibians','reptiles'],'non-mammals')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([data['Warm-blooded'],data['Gives Birth']],data['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "Y = data['Class']\n",
    "X = data.drop(['Name','Class'],axis=1)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy',max_depth=3)\n",
    "clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus \n",
    "from IPython.display import Image\n",
    "import os\n",
    "\n",
    "os.environ['PATH'] = os.environ['PATH']+';'+os.environ['CONDA_PREFIX']+r\"\\Library\\bin\\graphviz\"\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, feature_names=X.columns, class_names=['mammals','non-mammals'], filled=True, \n",
    "                                out_file=None) \n",
    "graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = [['gila monster',0,0,0,0,1,1,'non-mammals'],\n",
    "           ['platypus',1,0,0,0,1,1,'mammals'],\n",
    "           ['owl',1,0,0,1,1,0,'non-mammals'],\n",
    "           ['dolphin',1,1,1,0,0,0,'mammals']]\n",
    "testData = pd.DataFrame(testData, columns=data.columns)\n",
    "testData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY = testData['Class']\n",
    "testX = testData.drop(['Name','Class'],axis=1)\n",
    "\n",
    "predY = clf.predict(testX)\n",
    "predictions = pd.concat([testData['Name'],pd.Series(predY,name='Predicted Class')], axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy on test data is %.2f' % (accuracy_score(testY, predY)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "N = 1500\n",
    "\n",
    "mean1 = [6, 14]\n",
    "mean2 = [10, 6]\n",
    "mean3 = [14, 14]\n",
    "cov = [[3.5, 0], [0, 3.5]]  # diagonal covariance\n",
    "\n",
    "np.random.seed(50)\n",
    "X = np.random.multivariate_normal(mean1, cov, int(N/6))\n",
    "X = np.concatenate((X, np.random.multivariate_normal(mean2, cov, int(N/6))))\n",
    "X = np.concatenate((X, np.random.multivariate_normal(mean3, cov, int(N/6))))\n",
    "X = np.concatenate((X, 20*np.random.rand(int(N/2),2)))\n",
    "Y = np.concatenate((np.ones(int(N/2)),np.zeros(int(N/2))))\n",
    "\n",
    "plt.plot(X[:int(N/2),0],X[:int(N/2),1],'r+',X[int(N/2):,0],X[int(N/2):,1],'k.',ms=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Training and Test set creation\n",
    "#########################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.8, random_state=1)\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#########################################\n",
    "# Model fitting and evaluation\n",
    "#########################################\n",
    "\n",
    "maxdepths = [2,3,4,5,6,7,8,9,10,15,20,25,30,35,40,45,50]\n",
    "\n",
    "trainAcc = np.zeros(len(maxdepths))\n",
    "testAcc = np.zeros(len(maxdepths))\n",
    "\n",
    "index = 0\n",
    "for depth in maxdepths:\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    clf = clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.predict(X_train)\n",
    "    Y_predTest = clf.predict(X_test)\n",
    "    trainAcc[index] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAcc[index] = accuracy_score(Y_test, Y_predTest)\n",
    "    index += 1\n",
    "    \n",
    "#########################################\n",
    "# Plot of training and test accuracies\n",
    "#########################################\n",
    "    \n",
    "plt.plot(maxdepths,trainAcc,'ro-',maxdepths,testAcc,'bv--')\n",
    "plt.legend(['Training Accuracy','Test Accuracy'])\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) K-Nearest Neighbor Classifier (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "numNeighbors = [1, 5, 10, 15, 20, 25, 30]\n",
    "trainAcc = []\n",
    "testAcc = []\n",
    "\n",
    "for k in numNeighbors:\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.predict(X_train)\n",
    "    Y_predTest = clf.predict(X_test)\n",
    "    trainAcc.append(accuracy_score(Y_train, Y_predTrain))\n",
    "    testAcc.append(accuracy_score(Y_test, Y_predTest))\n",
    "\n",
    "plt.plot(numNeighbors, trainAcc, 'ro-', numNeighbors, testAcc,'bv--')\n",
    "plt.legend(['Training Accuracy','Test Accuracy'])\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Linear Classifier (Logistic regression, Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "C = [0.01, 0.1, 0.2, 0.5, 0.8, 1, 5, 10, 20, 50]\n",
    "LRtrainAcc = []\n",
    "LRtestAcc = []\n",
    "SVMtrainAcc = []\n",
    "SVMtestAcc = []\n",
    "\n",
    "for param in C:\n",
    "    clf = linear_model.LogisticRegression(C=param)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.predict(X_train)\n",
    "    Y_predTest = clf.predict(X_test)\n",
    "    LRtrainAcc.append(accuracy_score(Y_train, Y_predTrain))\n",
    "    LRtestAcc.append(accuracy_score(Y_test, Y_predTest))\n",
    "\n",
    "    clf = SVC(C=param,kernel='linear')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.predict(X_train)\n",
    "    Y_predTest = clf.predict(X_test)\n",
    "    SVMtrainAcc.append(accuracy_score(Y_train, Y_predTrain))\n",
    "    SVMtestAcc.append(accuracy_score(Y_test, Y_predTest))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))\n",
    "ax1.plot(C, LRtrainAcc, 'ro-', C, LRtestAcc,'bv--')\n",
    "ax1.legend(['Training Accuracy','Test Accuracy'])\n",
    "ax1.set_xlabel('C')\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "\n",
    "ax2.plot(C, SVMtrainAcc, 'ro-', C, SVMtestAcc,'bv--')\n",
    "ax2.legend(['Training Accuracy','Test Accuracy'])\n",
    "ax2.set_xlabel('C')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Non-linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "C = [0.01, 0.1, 0.2, 0.5, 0.8, 1, 5, 10, 20, 50]\n",
    "SVMtrainAcc = []\n",
    "SVMtestAcc = []\n",
    "\n",
    "for param in C:\n",
    "    clf = SVC(C=param,kernel='rbf',gamma='auto')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.predict(X_train)\n",
    "    Y_predTest = clf.predict(X_test)\n",
    "    SVMtrainAcc.append(accuracy_score(Y_train, Y_predTrain))\n",
    "    SVMtestAcc.append(accuracy_score(Y_test, Y_predTest))\n",
    "\n",
    "plt.plot(C, SVMtrainAcc, 'ro-', C, SVMtestAcc,'bv--')\n",
    "plt.legend(['Training Accuracy','Test Accuracy'])\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting, Bagging, Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "numBaseClassifiers = 500\n",
    "maxdepth = 10\n",
    "trainAcc = []\n",
    "testAcc = []\n",
    "\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=numBaseClassifiers)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_predTrain = clf.predict(X_train)\n",
    "Y_predTest = clf.predict(X_test)\n",
    "trainAcc.append(accuracy_score(Y_train, Y_predTrain))\n",
    "testAcc.append(accuracy_score(Y_test, Y_predTest))\n",
    "\n",
    "clf = ensemble.BaggingClassifier(DecisionTreeClassifier(max_depth=maxdepth),n_estimators=numBaseClassifiers)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_predTrain = clf.predict(X_train)\n",
    "Y_predTest = clf.predict(X_test)\n",
    "trainAcc.append(accuracy_score(Y_train, Y_predTrain))\n",
    "testAcc.append(accuracy_score(Y_test, Y_predTest))\n",
    "\n",
    "clf = ensemble.AdaBoostClassifier(DecisionTreeClassifier(max_depth=maxdepth),n_estimators=numBaseClassifiers)\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_predTrain = clf.predict(X_train)\n",
    "Y_predTest = clf.predict(X_test)\n",
    "trainAcc.append(accuracy_score(Y_train, Y_predTrain))\n",
    "testAcc.append(accuracy_score(Y_test, Y_predTest))\n",
    "\n",
    "methods = ['Random Forest', 'Bagging', 'AdaBoost']\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))\n",
    "ax1.bar([1.5,2.5,3.5], trainAcc)\n",
    "ax1.set_xticks([1.5,2.5,3.5])\n",
    "ax1.set_xticklabels(methods)\n",
    "ax2.bar([1.5,2.5,3.5], testAcc)\n",
    "ax2.set_xticks([1.5,2.5,3.5])\n",
    "ax2.set_xticklabels(methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## สรุปเนื้อหา\n",
    "\n",
    "1. Decision Tree\n",
    "\n",
    "2. Overfitting\n",
    "\n",
    "3. K-Nearest Neighbor\n",
    "\n",
    "4. Linear Classifier : Logistic Regression, Support Vector Machine\n",
    "\n",
    "5. Non-linear SVM\n",
    "\n",
    "6. Ensemble : Boosting, Bagging, Random Forrest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
