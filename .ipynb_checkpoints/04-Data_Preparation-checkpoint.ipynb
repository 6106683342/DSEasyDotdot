{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Preparation\n",
    "\n",
    "    เพื่อเตรียมข้อมูลให้พร้อมก่อนการนำไปวิเคราะห์ และสร้างโมเดล มีหลายเทคนิค เช่น Cleaning, Selecting, Transforming\n",
    "\n",
    "                                                                                        Data Science ง่าย . . by New ew ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "แก้ไขปัญหาที่อาจเกิดจากข้อมูลที่คุณภาพไม่ดีต่างๆ เช่น Noise, Outliers, Missing values, Duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', header=None)\n",
    "data.columns = ['Sample code', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "                'Normal Nucleoli', 'Mitoses','Class']\n",
    "\n",
    "data = data.drop(['Sample code'],axis=1)\n",
    "print('Number of instances = %d' % (data.shape[0]))\n",
    "print('Number of attributes = %d' % (data.shape[1]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"max_rows\", None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "import numpy as np\n",
    "\n",
    "data = data.replace('?',np.NaN)\n",
    "\n",
    "print('Number of instances = %d' % (data.shape[0]))\n",
    "print('Number of attributes = %d' % (data.shape[1]))\n",
    "\n",
    "print('Number of missing values:')\n",
    "for col in data.columns:\n",
    "    print('\\t%s: %d' % (col,data[col].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data['Bare Nuclei']\n",
    "\n",
    "print('Before replacing missing values:')\n",
    "print(data2[20:25])\n",
    "data2 = data2.fillna(data2.median())\n",
    "\n",
    "print('\\nAfter replacing missing values:')\n",
    "print(data2[20:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows in original data = %d' % (data.shape[0]))\n",
    "\n",
    "data2 = data.dropna()\n",
    "print('Number of rows after discarding missing values = %d' % (data2.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers\n",
    "%matplotlib inline\n",
    "\n",
    "data2 = data.drop(['Class'],axis=1)\n",
    "data2['Bare Nuclei'] = pd.to_numeric(data2['Bare Nuclei'])\n",
    "data2.boxplot(figsize=(20,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = (data2-data2.mean())/data2.std()\n",
    "Z[20:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows before discarding outliers = %d' % (Z.shape[0]))\n",
    "\n",
    "Z2 = Z.loc[((Z > -3).sum(axis=1)==9) & ((Z <= 3).sum(axis=1)==9),:]\n",
    "print('Number of rows after discarding missing values = %d' % (Z2.shape[0]))\n",
    "print(Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate Data\n",
    "dups = data.duplicated()\n",
    "print('Number of duplicate rows = %d' % (dups.sum()))\n",
    "data.loc[[11,28]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows before discarding duplicates = %d' % (data.shape[0]))\n",
    "data2 = data.drop_duplicates()\n",
    "print('Number of rows after discarding duplicates = %d' % (data2.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เป็นการรวมข้อมูลหลายๆ ข้อมูลให้เหลือข้อมูลเดียว เพื่อ 1) ลดขนาดของข้อมูล 2) ปรับมุมมองการวิเคราะห์ข้อมูล 3) เพิ่มความเสถียรของข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily precipitation time series data for weather station located at Detroit Metro Airport\n",
    "daily = pd.read_csv('04_DTW_prec.csv', header='infer')\n",
    "daily.index = pd.to_datetime(daily['DATE'])\n",
    "daily = daily['PRCP']\n",
    "ax = daily.plot(kind='line',figsize=(15,3))\n",
    "ax.set_title('Daily Precipitation (variance = %.4f)' % (daily.var()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = daily.groupby(pd.Grouper(freq='M')).sum()\n",
    "ax = monthly.plot(kind='line',figsize=(15,3))\n",
    "ax.set_title('Monthly Precipitation (variance = %.4f)' % (monthly.var()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual = daily.groupby(pd.Grouper(freq='Y')).sum()\n",
    "ax = annual.plot(kind='line',figsize=(15,3))\n",
    "ax.set_title('Annual Precipitation (variance = %.4f)' % (annual.var()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(n=3)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(frac=0.01, random_state=1)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(frac=0.01, replace=True, random_state=1)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Clump Thickness'].hist(bins=10)\n",
    "data['Clump Thickness'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = pd.cut(data['Clump Thickness'],4)\n",
    "bins.value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = pd.qcut(data['Clump Thickness'],4)\n",
    "bins.value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "numImages = 16\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "imgData = np.zeros(shape=(numImages,36963))\n",
    "\n",
    "for i in range(1,numImages+1):\n",
    "    filename = '04_pics/Picture'+str(i)+'.jpg'\n",
    "    img = mpimg.imread(filename)\n",
    "    ax = fig.add_subplot(4,4,i)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    ax.set_title(str(i))\n",
    "    imgData[i-1] = np.array(img.flatten()).reshape(1,img.shape[0]*img.shape[1]*img.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgData.shape, type(imgData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgData[5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "numComponents = 2\n",
    "pca = PCA(n_components=numComponents)\n",
    "pca.fit(imgData)\n",
    "\n",
    "projected = pca.transform(imgData)\n",
    "projected = pd.DataFrame(projected,columns=['pc1','pc2'],index=range(1,numImages+1))\n",
    "projected['food'] = ['burger', 'burger','burger','burger','drink','drink','drink','drink',\n",
    "                      'pasta', 'pasta', 'pasta', 'pasta', 'chicken', 'chicken', 'chicken', 'chicken']\n",
    "projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = {'burger':'b', 'drink':'r', 'pasta':'g', 'chicken':'k'}\n",
    "markerTypes = {'burger':'+', 'drink':'x', 'pasta':'o', 'chicken':'s'}\n",
    "\n",
    "for foodType in markerTypes:\n",
    "    d = projected[projected['food']==foodType]\n",
    "    plt.scatter(d['pc1'],d['pc2'],c=colors[foodType],s=60,marker=markerTypes[foodType])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## สรุปเนื้อหา\n",
    "\n",
    "1. Data Quality : Noise, Outliers, Missing values, Duplicate data\n",
    "\n",
    "2. Aggregation : Combine data 1) Reduce data size 2) Changning analysis 3) Stability of data\n",
    "\n",
    "3. Sampling : for exploratory data analysis and scale to big data applications, uncertainties\n",
    "\n",
    "4. Discretization : Transform continuous value to category\n",
    "\n",
    "5. Principal Component Analysis : Reducing number of attributes in the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
